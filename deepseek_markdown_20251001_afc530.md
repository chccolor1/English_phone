# 4

## KEEPING AI IN CHECK
(high int)

With great power comes great responsibility.

— Voltaire (popularized by Spider-Man)

In 2025, Netflix is leading the way in creative storytelling by setting clear rules for using generative artificial intelligence (AI) in making movies and shows. These guidelines help keep the art honest, creators safe, and viewers feeling confident "not to be taken for a ride."

Netflix considers generative AI—but calls it GenAI—a powerful creative tool. GenAI can help teams generate video, sound, text, and images fast and in unique ways. But the company knows rapid innovation can bring risks, especially when stories mix fact with fiction or when sensitive information is involved.

Because of these concerns, Netflix has published five key principles that partners must follow when using GenAI in production:

- **No copying others' work.** AI should not reproduce recognizable parts of someone else's copyrighted work. This helps prevent legal trouble and protects creative rights.
- **Don't train on production data.** AI tools must not store, reuse, or train on images, text, or other data used in the production. This keeps confidential information safe.
- **Use safe systems.** Whenever possible, AI tools should run in secure, enterprise-grade environments to protect inputs from leaks or misuse.
- **Keep generated content temporary.** Anything created by AI should not appear in the final product unless Netflix approves. The material is meant only for testing or planning, not final use.
- **Never replace real talent without consent.** AI must not generate voices or images that stand in for actors or union-covered work. Partners need explicit permission before touching on likeness or performance.

If partners can confidently follow all five principles, all they need to do is tell their Netflix contact about the GenAI use. But if they are unsure or can't meet the rules, they must get written approval before moving forward.

These rules were created after Netflix faced criticism from a documentary that used AI-generated images without clear disclosure. Viewers felt misled—especially in true-crime stories where authenticity matters. The controversy was a warning sign that shaping reality on screen must be done carefully.

Netflix isn't turning its back on GenAI, though. In fact, the company already used AI to create a dramatic building collapse scene in its sci-fi series The Eternaut. The result was ten times faster and cheaper than traditional effects work. This shows how AI can help, as long as it's used right.

The new guidelines balance innovation with ethics. They help creators continue being creative—but always under a responsible framework. It's like giving someone a fast car: Netflix wants them to drive safely, obey the rules, and keep everyone on board comfortable and secure.

By requiring transparency and a safety-first mindset, Netflix protects its brand and builds trust with viewers. In turn, film and show creators can use AI tools confidently, knowing what is allowed and what needs approval. And that is not only smart—it's setting a standard for the whole entertainment industry.

To sum it up: Netflix sees GenAI as a fantastic helper—but with big power comes big responsibility. So follow the rules, keep it on the level, and you'll stay in Netflix's good books. After all, in a world where technology races ahead, strong guidance keeps the show running smoothly.

## 01 Comprehension Questions

- What does Netflix call generative artificial intelligence?
- What should partners do if they are unsure or cannot meet the GenAI rules?
- What example did the article give about Netflix using AI successfully?

## 02 Discussion Questions

- Why do you think Netflix created special rules for GenAI in production?
- How can rules help balance creativity and responsibility when using new technology?
- Do you think viewers should always know if AI was used in a movie or show? Why or why not?